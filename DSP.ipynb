{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9bJK8rtd810"
      },
      "source": [
        "# Notebook to compare and explore raw images, model masks and manual masks\n",
        "\n",
        "In this notebook, we display a grid of all uploaded images. Each image group consists of:\n",
        "* **raw image**: the original art object's image\n",
        "    * Expected: image with an image extension (i.e. `.png`, `.jpeg` or `.jpg`)  (inside `./data/raw_images/`)\n",
        "* **model mask**: the model mask outputed by the Deeplab v3+ model\n",
        "    * Expected: image with the same name as the raw image and file extension (inside `./data/model_masks/`)\n",
        "* **manual mask**: the manual mask drawn by one of our team members\n",
        "    * Expected: image with the same name as the raw image and file extension (inside `./data/manual_masks/`)\n",
        "* **metrics' object**: the dict object containing the metrics.\n",
        "    * Expected: *.JSON* file with the same name as the raw image containing only top-level keys. The key is the metric's name and the value is the performance value of the metric.\n",
        "\n",
        "If there is a missing image, mask, metrics' object, etc. a \"missing file\" default image will be shown. Therefore, you don't need to provide everything for each raw image to start experimenting!\n",
        "\n",
        "There is a set of 101 images already prepared by Matt and it's available in the GitHub repo as a release. The cells below download, unzip and save this dataset inside `./data/raw_images/` and this serves as the common basis for everything else.\n",
        "\n",
        "You can also skip the cells downloading the data and place your own set of images inside `./data/raw_images/` and experiment from there.\n",
        "\n",
        "**When a session ends, the uploaded files are deleted, so this is not persistent storage!**\n",
        "\n",
        "Good luck!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jjLby-8e1sl"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B763b4z-d8Jh"
      },
      "outputs": [],
      "source": [
        "%pylab inline\n",
        "import math\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "from typing import Tuple, List\n",
        "import requests, zipfile, io\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZ0QjO0Ze4HQ"
      },
      "source": [
        "### Constants and paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLUDTSSB0OMD"
      },
      "outputs": [],
      "source": [
        "RAW_IMAGES_PATH = './data/raw_images/'\n",
        "MODEL_MASKS_PATH = './data/model_masks/'\n",
        "MANUAL_MASKS_PATH = './data/manual_masks/'\n",
        "METRICS_PATH = './data/metrics/'\n",
        "ENSEMBLE_MASKS_PATH = './data/ensemble_masks/'\n",
        "\n",
        "IMAGE_FILE_EXTENSIONS = ('png', 'jpeg', 'jpg')\n",
        "\n",
        "RAW_IMAGES_ZIP_URL = \"https://github.com/rijks-g4/rijksdraw/releases/download/v0.0.1/initial_dataset.zip\"\n",
        "MANUAL_MASKS_ZIP_URL = \"https://github.com/rijks-g4/rijksdraw/releases/download/v0.0.1/manual_masks.zip\"\n",
        "MODEL_MASKS_ZIP_URL = \"https://github.com/rijks-g4/rijksdraw/releases/download/v0.0.1/masks.zip\"\n",
        "\n",
        "MISSING_FILE_URL = 'https://cdn1.iconfinder.com/data/icons/leto-files/64/leto_files-58-512.png'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5ESG4Rie8D3"
      },
      "source": [
        "### Create required directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFgbIjhoz7Ne"
      },
      "outputs": [],
      "source": [
        "os.makedirs(RAW_IMAGES_PATH, exist_ok=True)\n",
        "os.makedirs(MODEL_MASKS_PATH, exist_ok=True)\n",
        "os.makedirs(MANUAL_MASKS_PATH, exist_ok=True)\n",
        "os.makedirs(METRICS_PATH, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNujKcZkfHro"
      },
      "source": [
        "### Download, unzip and save the raw images, manual masks and model masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMzWWiD37fH4"
      },
      "outputs": [],
      "source": [
        "def download_and_extract_nested_zip(zip_url: str, output_directory: str, nest_directory_name: str):\n",
        "    r = requests.get(zip_url)\n",
        "    with zipfile.ZipFile(io.BytesIO(r.content)) as zip_file:\n",
        "        for member in zip_file.namelist():\n",
        "            filename = os.path.basename(member)\n",
        "            # skip directories\n",
        "            if not filename or member != f'{nest_directory_name}/{filename}':\n",
        "                continue\n",
        "\n",
        "            # copy file (taken from zipfile's extract)\n",
        "            source = zip_file.open(member)\n",
        "            target = open(os.path.join(output_directory, filename), \"wb\")\n",
        "            with source, target:\n",
        "                shutil.copyfileobj(source, target)\n",
        "\n",
        "def download_and_extract_masks(zip_url: str, output_directory: str, nest_directory_name: str):\n",
        "    r = requests.get(zip_url)\n",
        "    with zipfile.ZipFile(io.BytesIO(r.content)) as zip_file:\n",
        "        for member in zip_file.namelist():\n",
        "            filename = os.path.basename(member)\n",
        "            output_path = member.replace(f'{nest_directory_name}/', \"\", 1)\n",
        "            output_path = os.path.join(output_directory, output_path)\n",
        "            # print(filename, member)\n",
        "            # skip directories\n",
        "            if not filename:\n",
        "                if output_path:\n",
        "                    os.makedirs(output_path, exist_ok = True)\n",
        "                continue            \n",
        "\n",
        "            # copy file (taken from zipfile's extract)\n",
        "            source = zip_file.open(member)\n",
        "            target = open(output_path, \"wb\")\n",
        "            with source, target:\n",
        "                shutil.copyfileobj(source, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oR0o_nwVEqW9"
      },
      "outputs": [],
      "source": [
        "download_and_extract_nested_zip(RAW_IMAGES_ZIP_URL, RAW_IMAGES_PATH, 'initial_dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_epG2ZZmE18W"
      },
      "outputs": [],
      "source": [
        "download_and_extract_nested_zip(MANUAL_MASKS_ZIP_URL, MANUAL_MASKS_PATH, 'manual_masks')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKFxCnceE67q"
      },
      "outputs": [],
      "source": [
        "download_and_extract_masks(MODEL_MASKS_ZIP_URL, MODEL_MASKS_PATH, 'masks')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw9_OSEfjcoC"
      },
      "source": [
        "# Before continuing, please:\n",
        "* Check whether the stats below (you need to run them) show the correct number of objects for each directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChmrPgrbfQ-7"
      },
      "source": [
        "### Show stats of read images and metrics' objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKaK6oJ16ch_"
      },
      "outputs": [],
      "source": [
        "def get_all_files(directory: str):\n",
        "    return [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
        "\n",
        "def get_all_dirs(directory: str):\n",
        "    return [f for f in os.listdir(directory) if os.path.isdir(os.path.join(directory, f))]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAMES = get_all_dirs(MODEL_MASKS_PATH)"
      ],
      "metadata": {
        "id": "b9-tOJfgNhKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fe9VdZYm6f5H"
      },
      "outputs": [],
      "source": [
        "raw_images = [f for f in get_all_files(RAW_IMAGES_PATH) if f.endswith(IMAGE_FILE_EXTENSIONS)]\n",
        "print(f\"Found {len(raw_images)} raw images.\")\n",
        "\n",
        "for model in get_all_dirs(MODEL_MASKS_PATH):\n",
        "    model_masks = get_all_files(os.path.join(MODEL_MASKS_PATH, model))\n",
        "    print(f\"Found {len(model_masks)} model masks for model: {model}.\")\n",
        "\n",
        "manual_masks = get_all_files(MANUAL_MASKS_PATH)\n",
        "print(f\"Found {len(manual_masks)} manual masks.\")\n",
        "\n",
        "metrics_objects = get_all_files(METRICS_PATH)\n",
        "print(f\"Found {len(metrics_objects)} metrics' objects.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions to read masks"
      ],
      "metadata": {
        "id": "aa6ob2XkRfNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def manual_mask_exists(img_filename: str) -> bool:\n",
        "    manual_mask_filename = f\"{img_filename.split('.')[0]}.json\"\n",
        "    return manual_mask_filename in manual_masks\n",
        "\n",
        "def read_manual_mask(mask_directory: str, img_filename: str):\n",
        "    mask_path = f\"{img_filename.split('.')[0]}.json\"\n",
        "    try:\n",
        "        with open(os.path.join(mask_directory, mask_path)) as json_file:\n",
        "            mask = json.load(json_file)\n",
        "            width = mask['imageWidth']\n",
        "            height = mask['imageHeight']\n",
        "\n",
        "            img = Image.new('L', (width, height), 0)\n",
        "\n",
        "            for shape in mask['shapes']:\n",
        "                ImageDraw.Draw(img).polygon([(point[0], point[1]) for point in shape['points']], outline=1, fill=1)\n",
        "\n",
        "            return (mask_path, np.array(img))\n",
        "    except FileNotFoundError as e:\n",
        "        return (mask_path, None)\n",
        "\n",
        "def read_model_mask(model_name: str, image_name: str):\n",
        "    mask_filename = f\"{image_name.split('.')[0]}.npy\"\n",
        "    full_mask_path = os.path.join(MODEL_MASKS_PATH, model_name, mask_filename)\n",
        "\n",
        "    mask = np.load(full_mask_path)\n",
        "\n",
        "    if model_name in ['mask_rcnn_coco']:\n",
        "        mask = np.logical_or.reduce(mask, axis=2).astype(int)\n",
        "\n",
        "    mask[mask == 255] = 1\n",
        "\n",
        "    return mask_filename, mask\n",
        "\n",
        "def read_image(img_path: str):\n",
        "    filename = os.path.basename(img_path)\n",
        "    try:\n",
        "        return (filename, mpimg.imread(img_path))\n",
        "    except FileNotFoundError as e:\n",
        "        return (filename, None)"
      ],
      "metadata": {
        "id": "eQ_UC6qWNsjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read manual masks"
      ],
      "metadata": {
        "id": "bwpOb6E9RjPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_images_with_manual_masks = [\n",
        "    raw_image for raw_image in raw_images if manual_mask_exists(raw_image)\n",
        "]\n",
        "\n",
        "print(raw_images_with_manual_masks)"
      ],
      "metadata": {
        "id": "1RkTeT3_RiiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions for evaluations"
      ],
      "metadata": {
        "id": "1vUK2nSMRqqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def iou_score(target, prediction):\n",
        "    intersection = np.logical_and(target, prediction)\n",
        "    union = np.logical_or(target, prediction)\n",
        "    return np.sum(intersection.astype(int)) / np.sum(union.astype(int))\n",
        "\n",
        "def pixel_accuracy_score(target, prediction):\n",
        "    accurate_pixels = np.logical_or(np.logical_and(target, prediction), np.logical_and(np.logical_not(target), np.logical_not(prediction)))\n",
        "    all_pixels = np.logical_or(target, np.logical_not(target))\n",
        "    return np.sum(accurate_pixels.astype(int)) / np.sum(all_pixels.astype(int))\n",
        "\n",
        "def dice_coefficient_score(target, prediction):\n",
        "    intersection = np.logical_and(target, prediction)\n",
        "    return 2 * np.sum(intersection.astype(int)) / (np.sum(target.astype(int)) + np.sum(prediction.astype(int)))\n",
        "\n",
        "def calculate_metrics(manual_mask, model_mask):\n",
        "    metrics = dict()\n",
        "\n",
        "    metrics['Dice Coefficient'] = dice_coefficient_score(manual_mask, model_mask)\n",
        "    metrics['IoU Score'] = iou_score(manual_mask, model_mask)\n",
        "    metrics['PA Score'] = pixel_accuracy_score(manual_mask, model_mask)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def metrics_average(metrics):\n",
        "    average = defaultdict(dict)\n",
        "\n",
        "    for key in metrics[0]:\n",
        "        for metric in metrics[0][key]:\n",
        "            average[key][metric] = dict()\n",
        "            all_scores = [metrics[i][key][metric] for i in range(len(metrics))]\n",
        "            average[key][metric]['mean'] = sum(all_scores) / len(all_scores)\n",
        "            average[key][metric]['min'] = min(all_scores)\n",
        "            average[key][metric]['max'] = max(all_scores)\n",
        "\n",
        "    return average\n",
        "\n",
        "def print_metrics_overview(metrics):\n",
        "    print(\"\\nAverage Metrics (Min, Mean, Max):\\n\")\n",
        "    average = metrics_average(metrics)\n",
        "    for key in average:\n",
        "        for metric, value in average[key].items():\n",
        "            print(f\"{key}, {metric}: {round(value['min'], 2)}, {round(value['mean'], 2)}, {round(value['max'], 2)}\")\n",
        "    print(\"\")"
      ],
      "metadata": {
        "id": "hQV-zbxKRsvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ensemble"
      ],
      "metadata": {
        "id": "gP77dY3MWigm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8ol3QSQjSwQ"
      },
      "outputs": [],
      "source": [
        "def ensemble_sum_mask(masks: list, threshold: float = None):\n",
        "    ensemble = masks[0]\n",
        "\n",
        "    for mask in masks[1:]:\n",
        "        ensemble = np.add(ensemble, mask)\n",
        "\n",
        "    if threshold is not None:\n",
        "        ensemble = np.where(ensemble >= threshold, ensemble, 0)\n",
        "\n",
        "    return ensemble"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show a grid of raw images, model masks, ground truth (i.e. manually drawn masks) and metrics"
      ],
      "metadata": {
        "id": "Kf7VlmfLVr7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Tuple\n",
        "\n",
        "def show_groups_galery(\n",
        "    data: List[Tuple],\n",
        "    fig_size: Tuple[int, int],\n",
        "    col_headers: List[str] = None,\n",
        "    row_headers: List[str] = None,\n",
        "    metrics: List[str] = None) -> None:\n",
        "    # Basic stats\n",
        "    n_rows = len(data)\n",
        "    n_cols = len(data[0]) if metrics is None else len(data[0]) + 1\n",
        "    print(f\"Showing {n_rows * n_cols} images...\")\n",
        "    print(f\"Columns: {n_cols}\")\n",
        "    print(f\"Rows : {n_rows}\")\n",
        "\n",
        "    # Create galery figure\n",
        "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(fig_size[0] * n_cols, fig_size[1] * n_rows))\n",
        "    fig.tight_layout()\n",
        "\n",
        "    if col_headers:\n",
        "        # Add col headers\n",
        "        first_col = axs[:,0] if n_rows > 1 else axs\n",
        "        for ax, row in zip(first_col, col_headers):\n",
        "            ax.annotate(row, xy=(0, 0.5), xytext=(-ax.yaxis.labelpad - 5, 0),\n",
        "                        xycoords=ax.yaxis.label, textcoords='offset points',\n",
        "                        size='xx-large', ha='right', va='center')\n",
        "\n",
        "    if row_headers:\n",
        "        # Add row headers\n",
        "        first_row = axs[0] if n_rows > 1 else axs\n",
        "        for ax, col in zip(first_row, row_headers):\n",
        "            ax.annotate(col, xy=(0.5, 1), xytext=(0, 30),\n",
        "                        xycoords='axes fraction', textcoords='offset points',\n",
        "                        size='large', ha='center', va='baseline')\n",
        "\n",
        "    # Show each group of images\n",
        "    for row_id, data_group in enumerate(data):\n",
        "        for col_id, (image_name, image) in enumerate(data_group):\n",
        "            ax = axs[row_id, col_id] if n_rows > 1 else axs[col_id]\n",
        "            ax.set_title(image_name)\n",
        "            if image is not None:\n",
        "                ax.imshow(image)\n",
        "\n",
        "        # metrics_path = metrics_paths[row_id]\n",
        "        metrics_object = metrics[row_id]\n",
        "        ax = axs[row_id, n_cols - 1]\n",
        "        # ax.set_title(os.path.basename(metrics_path))\n",
        "\n",
        "        try:\n",
        "            # with open(metrics_path) as json_file:\n",
        "                # metrics = json.load(json_file)\n",
        "            ax.axis([0, 10, 0, 10])\n",
        "            for idx, model in enumerate(metrics_object):\n",
        "                for idx2, (metric_name, value) in enumerate(metrics_object[model].items()):\n",
        "                    ax.text(1, 10 - ((((idx * 3) + idx2) * 0.3) + 1),\n",
        "                            f\"{model} - {metric_name}: {round(value, 2)}\",\n",
        "                            fontsize=15, style='italic')\n",
        "        except FileNotFoundError as e:\n",
        "            pass\n",
        "            # Show missing file image if metrics' file wasn't found\n",
        "            # image = mpimg.imread(MISSING_FILE_URL)\n",
        "            # ax.imshow(image)\n",
        "\n",
        "def show_galery_from_paths(\n",
        "    data: List[List[str]],\n",
        "    fig_size: Tuple[int, int],\n",
        "    col_headers: List[str] = None,\n",
        "    row_headers: List[str] = None,\n",
        "    metrics_paths: str = None) -> None:\n",
        "    \n",
        "    images = list()\n",
        "    \n",
        "    for data_group in data:\n",
        "        images_group = list()\n",
        "        for image_path in data_group:\n",
        "            filename = os.path.basename(image_path)\n",
        "            try:\n",
        "                images_group.append((\n",
        "                    filename,\n",
        "                    mpimg.imread(image_path)\n",
        "                ))\n",
        "            except FileNotFoundError as e:\n",
        "                images_group.append((filename, None))\n",
        "        images.append(images_group)\n",
        "\n",
        "    show_groups_galery(\n",
        "        images,\n",
        "        fig_size,\n",
        "        col_headers,\n",
        "        row_headers,\n",
        "        metrics_paths,\n",
        "    )"
      ],
      "metadata": {
        "id": "wOv-TYMFVoZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOKt8BpAlLC-"
      },
      "outputs": [],
      "source": [
        "# Set the galery size. First value is the column width, second value is the row height.\n",
        "FIG_SIZE = (9, 8)\n",
        "\n",
        "image_sets = list()\n",
        "metrics = list()\n",
        "\n",
        "# Swap the two lines below if you want to experiment with only the first X images.\n",
        "for raw_image_name in raw_images_with_manual_masks:\n",
        "# for raw_image_name in raw_images:\n",
        "    raw_image_object = read_image(os.path.join(RAW_IMAGES_PATH, raw_image_name))\n",
        "    manual_mask_object = read_manual_mask(MANUAL_MASKS_PATH, raw_image_name)\n",
        "\n",
        "    # models = list()\n",
        "    metrics_object = defaultdict(dict)\n",
        "    model_mask_objects = list()\n",
        "\n",
        "    for model in MODEL_NAMES:\n",
        "        if model == 'fcn_resnet101_masks':\n",
        "            continue\n",
        "\n",
        "        model_mask_object = read_model_mask(model, raw_image_name)\n",
        "\n",
        "        # models.append(model)\n",
        "        model_mask_objects.append(model_mask_object)\n",
        "        metrics_object[model] = calculate_metrics(manual_mask_object[1], model_mask_object[1])\n",
        "\n",
        "    # ensemble_models = list()\n",
        "    # ensemble_mask_objects = list()\n",
        "\n",
        "    for threshold in range(1, 5):\n",
        "        ensemble_name = f'Sum ensemble: {threshold}'\n",
        "        sum_ensemble = (\n",
        "            ensemble_name,\n",
        "            ensemble_sum_mask([m[1] for m in model_mask_objects], threshold = threshold)\n",
        "        )\n",
        "\n",
        "        # ensemble_models.append(ensemble_name)\n",
        "        # ensemble_mask_objects.append(sum_ensemble)\n",
        "        metrics_object[ensemble_name] = calculate_metrics(manual_mask_object[1], sum_ensemble[1])\n",
        "\n",
        "    # models.extend(ensemble_models)\n",
        "    # model_mask_objects.extend(ensemble_mask_objects)\n",
        "\n",
        "    # image_sets.append(\n",
        "    #     (\n",
        "    #         raw_image_object,\n",
        "    #         manual_mask_object,\n",
        "    #         *model_mask_objects,\n",
        "    #     )\n",
        "    # )\n",
        "    metrics.append(metrics_object)\n",
        "    # metrics.append(os.path.join(METRICS_PATH, f\"{raw_image_name.split('.')[0]}.json\"))\n",
        "\n",
        "print(f\"Created {len(image_sets)} image sets.\")\n",
        "\n",
        "# print_metrics_overview(metrics)\n",
        "\n",
        "# show_groups_galery(image_sets, FIG_SIZE, None, ['Raw', 'Manual Mask', *models, 'Metrics'], metrics)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# m_average = metrics_average(metrics)\n",
        "\n",
        "# with open('/content/data/average_metrics.json', 'w') as f:\n",
        "#     json.dump(m_average, f)\n",
        "\n",
        "with open('/content/data/metrics.json', 'w') as f:\n",
        "    metrics_res = dict()\n",
        "\n",
        "    for (raw_image_name, metric) in zip(raw_images_with_manual_masks, metrics):\n",
        "        object_number = raw_image_name.split('.')[0]\n",
        "        metrics_res[object_number] = metric\n",
        "\n",
        "    json.dump(metrics_res, f)"
      ],
      "metadata": {
        "id": "eBePmwtrSRF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1wVUuq6RbKh"
      },
      "outputs": [],
      "source": [
        "print_metrics_overview(metrics)\n",
        "\n",
        "fig = plt.figure(figsize =(10, 7))\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "metrics_keys = []\n",
        "metrics_list = []\n",
        "for idx, key in enumerate(metrics[0]):\n",
        "    metric_values = []\n",
        "    for metric_object in metrics:\n",
        "        metric_values.append(metric_object[key])\n",
        "    metrics_list.append(metric_values)\n",
        "    metrics_keys.append(key)\n",
        "\n",
        "# Creating plot\n",
        "plt.boxplot(metrics_list, vert = False )\n",
        "\n",
        "ax.set(xlim=(0, 1))\n",
        "ax.set_yticklabels(metrics_keys)\n",
        " \n",
        "# show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mB2lSmu-To9U"
      },
      "outputs": [],
      "source": [
        "#Ensemble - Matt & Rutger\n",
        "FIG_SIZE = (9, 8)\n",
        "\n",
        "image_sets = list()\n",
        "metrics = list()\n",
        "\n",
        "for raw_image_name in [\"unnamed-22.jpg\",\"unnamed-25.jpg\", \"unnamed-26.jpg\", \"unnamed-27.jpg\", \"unnamed-28.jpg\"]: #smaller sample for testing purposes \n",
        "    raw_image_object = read_image(os.path.join(RAW_IMAGES_PATH, raw_image_name))\n",
        "    manual_mask_object = read_manual_mask(MANUAL_MASKS_PATH, raw_image_name)\n",
        "    model_mask_object = read_model_mask(MODEL_MASKS_PATH, raw_image_name, os.path.join(RAW_IMAGES_PATH, raw_image_name))\n",
        "    segformer_mask_object = read_segformer_mask(SEGFORMER_MASKS_PATH, raw_image_name)\n",
        "    unet_mask_object = read_unet_mask(UNET_MASKS_PATH, raw_image_name)\n",
        "    ensemble_mask_object = read_ensemble_mask(model_mask_object[1], segformer_mask_object[1], unet_mask_object[1], threshold=2, noise=False)\n",
        "    ensemble_mask_object_2 = read_ensemble_mask(model_mask_object[1], segformer_mask_object[1], unet_mask_object[1], threshold=3, noise=False)\n",
        "\n",
        "    ensemble_mask_object_2\n",
        "\n",
        "    with open(os.path.join(ENSEMBLE_MASKS_PATH, f'{raw_image_name[:-4]}.npy'), 'wb') as f:\n",
        "        np.save(f, ensemble_mask_object_2)\n",
        "\n",
        "    image_sets.append(\n",
        "        (\n",
        "            raw_image_object,\n",
        "            (raw_image_name, ensemble_mask_object),\n",
        "            (raw_image_name, ensemble_mask_object_2),\n",
        "        )\n",
        "    )\n",
        "    metrics.append({\n",
        "        'Ens-1 - IoU Score': iou_score(manual_mask_object[1], ensemble_mask_object),\n",
        "        'Ens-1 - PA Score': pixel_accuracy_score(manual_mask_object[1], ensemble_mask_object),\n",
        "        'Ens-1 - Dice Coefficient': dice_coefficient_score(manual_mask_object[1], ensemble_mask_object),\n",
        "        'Ens-2 - IoU Score': iou_score(manual_mask_object[1], ensemble_mask_object_2),\n",
        "        'Ens-2 - PA Score': pixel_accuracy_score(manual_mask_object[1], ensemble_mask_object_2),\n",
        "        'Ens-2 - Dice Coefficient': dice_coefficient_score(manual_mask_object[1], ensemble_mask_object_2),\n",
        "    })\n",
        "    # metrics.append(os.path.join(METRICS_PATH, f\"{raw_image_name.split('.')[0]}.json\"))\n",
        "\n",
        "print(f\"Created {len(image_sets)} image sets.\")\n",
        "\n",
        "print_metrics_overview(metrics)\n",
        "\n",
        "show_groups_galery(image_sets, FIG_SIZE, None, ['Raw','Ens-1', 'Ens-2', 'Metrics'], metrics)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7U9Ct3yb69WD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OLD EXPERIMENTS"
      ],
      "metadata": {
        "id": "_PI2at6bROZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RUTGER TEST BLOCK\n",
        "m1 = np.array([[0,0,255],\n",
        "               [255,255,0],\n",
        "               [0,255,255]])\n",
        "\n",
        "m2 = np.array([[2,2,2],\n",
        "               [2,2,0],\n",
        "               [0,0,0]])\n",
        "\n",
        "masks = [m1, m2]\n",
        "\n",
        "wm = weighted_mask(masks)\n",
        "vote_mask(wm, 2)"
      ],
      "metadata": {
        "id": "o6e3CTtLVk6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_ensemble_mask(model_mask_object, segformer_mask_object, unet_mask_object, noise, threshold):\n",
        "\n",
        "    m1=segformer_mask_object ##255 for something, 0 for nothing\n",
        "    for i in range(len(m1)):\n",
        "      for j in range(len(m1[i])):\n",
        "        if m1[i][j] == 255:\n",
        "         m1[i][j] = 1\n",
        "    m2=model_mask_object ##1 for something, 0 for nothing\n",
        "    m3=unet_mask_object ##1 for something, 0 for nothing\n",
        "    m4=np.add(m1,m2)\n",
        "    m5=np.add(m3,m4)\n",
        "\n",
        "    if noise==False:\n",
        "     for i in range(len(m5)):\n",
        "       for j in range(len(m5[i])):\n",
        "         if m5[i][j] >= threshold:\n",
        "           m5[i][j] = 1\n",
        "         elif m5[i][j] < threshold:\n",
        "           m5[i][j] = 0\n",
        "\n",
        "    return m5"
      ],
      "metadata": {
        "id": "a_hRqmMJZECb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale(im, nR, nC):\n",
        "  nR0 = len(im)     # source number of rows \n",
        "  nC0 = len(im[0])  # source number of columns \n",
        "  return [[ im[int(nR0 * r / nR)][int(nC0 * c / nC)]  \n",
        "             for c in range(nC)] for r in range(nR)]\n",
        "\n",
        "def weighted_mask(masks):\n",
        "    weighted = np.zeros(np.shape(masks[0]))\n",
        "    for mask in masks:\n",
        "        mask = mask/mask\n",
        "        mask[np.isnan(mask)] = 0\n",
        "        weighted += mask\n",
        "    return weighted\n",
        "\n",
        "def vote_mask(weighted_mask, threshold):\n",
        "    weighted_mask[weighted_mask < threshold] = 0\n",
        "    weighted_mask[weighted_mask >= threshold] = 1\n",
        "    return weighted_mask"
      ],
      "metadata": {
        "id": "88jOCBgvZr95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ensemble_mask_object = read_ensemble_mask(model_mask_object[1], segformer_mask_object[1], unet_mask_object[1], threshold=2, noise=False)\n",
        "# ensemble_mask_object_2 = read_ensemble_mask(model_mask_object[1], segformer_mask_object[1], unet_mask_object[1], threshold=3, noise=False)\n",
        "\n",
        "# weighted_mask_object = weighted_mask([m[1] for m in model_mask_objects]) \n",
        "# vote_mask_object = vote_mask(weighted_mask_object, threshold=3)"
      ],
      "metadata": {
        "id": "Ty6oCLeoZ1tS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#manually drawn mask\n",
        "sample_manual_mask = read_manual_mask(MANUAL_MASKS_PATH, raw_images_with_manual_masks[0])\n",
        "plt.imshow(sample_manual_mask[1])\n",
        "\n",
        "#mask output from model-1\n",
        "sample_segformer_mask_name, sample_segformer_mask = read_model_mask(\n",
        "    'segformer_masks',\n",
        "    raw_images_with_manual_masks[0]\n",
        ")\n",
        "plt.imshow(sample_segformer_mask)\n",
        "\n",
        "#mask output from model-2\n",
        "sample_model_mask = read_model_mask('mask_rcnn_coco', raw_images_with_manual_masks[0])\n",
        "plt.imshow(sample_model_mask[1])\n",
        "\n",
        "#mask output from model-3\n",
        "sample_unet_mask_name, sample_unet_mask = read_model_mask('unet', raw_images_with_manual_masks[0])\n",
        "plt.imshow(sample_unet_mask)\n",
        "\n",
        "sample_metrics = {\n",
        "    'IoU Score': iou_score(sample_manual_mask[1], sample_model_mask[1]),\n",
        "    'PA Score': pixel_accuracy_score(sample_manual_mask[1], sample_model_mask[1]),\n",
        "    'Dice Coefficient': dice_coefficient_score(sample_manual_mask[1], sample_model_mask[1])\n",
        "}\n",
        "\n",
        "print('Metrics:')\n",
        "print(sample_metrics)"
      ],
      "metadata": {
        "id": "mT2d5-TyRQc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e = ensemble_sum_mask([sample_model_mask[1], sample_segformer_mask], threshold=2)\n",
        "plt.imshow(e)"
      ],
      "metadata": {
        "id": "1XTEATbjeAnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(sum_ensemble[1])"
      ],
      "metadata": {
        "id": "7LPBMU-weJ76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wow = list()\n",
        "\n",
        "for threshold in range(1, 2):\n",
        "    ensemble_name = f'Sum ensemble: {threshold}'\n",
        "    sum_ensemble = (\n",
        "        ensemble_name,\n",
        "        ensemble_sum_mask([m[1] for m in model_mask_objects], threshold = threshold)\n",
        "    )\n",
        "    wow.append(sum_ensemble)"
      ],
      "metadata": {
        "id": "rgW5hHnjgZ54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e = wow[0][1]"
      ],
      "metadata": {
        "id": "gE1_B7lVgkc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(e[e > 2])"
      ],
      "metadata": {
        "id": "OBFMu5_GgoCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ms = [m for m in model_mask_objects]"
      ],
      "metadata": {
        "id": "VWhZ_kaOgpWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for m in model_mask_objects:\n",
        "    print(m[0])\n",
        "    m = m[1]\n",
        "    print(m[m > 1])"
      ],
      "metadata": {
        "id": "g93y802OhegH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cM-8EmyMhhei"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DSP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}